---
title: "Bayesian Approaches"
author: "Peter von Rohr"
date: "2021-03-29"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::knit_hooks$set(hook_convert_odg = rmdhelp::hook_convert_odg)
```



## Statistics

The world of statistics is divided into

* __Frequentists__ and 
* __Bayesians__

Divergence in 

* understanding of probability
* differentiation between components of a model and the data
* techniques to estimate parameters



## F vs B
```{r FreqBayesTable, eval=TRUE, echo=FALSE, results='asis'}
Topic <- c("Probability", "Model and Data", "Parameter Estimation")
Frequentists <- c("Ratio between cardinalities of sets",
                   "Parameter are unknown, data are known",
                   "ML or REML are used for parameter estimation")
Bayesians <-  c("Measure of uncertainty",
                 "Differentiation between knowns and unknowns",
                 "MCMC techniques to approximate posterior distributions")
dfTabCaptOut <- tibble::tibble(Topic         = Topic,
                           Frequentists  = Frequentists,
                           Bayesians     = Bayesians)
knitr::kable(dfTabCaptOut, 
             format = "latex", 
             align = c("p{2cm}","p{3.5cm}","p{3.5cm}"))
```



## Linear Model
\begin{equation}
y_i = \beta_0 + \beta_1 x_{i1} + \epsilon_i \notag
\end{equation}

```{r BayesianUnKnowsTab, eval=TRUE, echo=FALSE, results='asis'}
Term <- c("$y_i$", "$x_1$", "$\\beta_0$", "$\\beta_1$", "$\\sigma^2$")
Known <- c("X", "X", "", "", "X")
Unknown <- c("", "", "X", "X", "")
knitr::kable(tibble::tibble(Term = Term,
                        Known = Known,
                        Unknown = Unknown), 
             format = "latex", 
             align = c("c","c","c"),
             escape = FALSE,
             caption = "Separation Into Knowns And Unknowns")
```




## Example Dataset

```{r dataregression, echo=FALSE, results='asis'}
tbl_reg <- tibble::tibble(Animal = c(1:10),
                          `Breast Circumference` = c(176, 177, 178, 179, 179, 180, 181, 182,183, 184),
                          `Body Weight` = c(471, 463, 481, 470, 496, 491, 518, 511, 510, 541))
knitr::kable(tbl_reg,
             booktabs = TRUE,
             caption = "Dataset for Regression of Body Weight on Breast Circumference for ten Animals")
```



## Estimation Of Unknowns
* Estimates of unknowns $\beta = \left[\begin{array}{c} \beta_0  \\  \beta_1 \end{array} \right]$
* Using Bayes Theorem:

\begin{align}
f(\beta | y) & =       \frac{f(\beta, y)}{f(y)} \notag \\
             & =       \frac{f(y | \beta)f(\beta)}{f(y)} \notag \\
             & \propto  f(y | \beta)f(\beta) \notag
\end{align}

where $f(\beta)$: prior distribution  and  $f(y|\beta)$: likelihood


## Prior and Posterior
```{r asmbayespriorposterior, echo=FALSE, hook_convert_odg=TRUE, fig_path="odg", fig.cap="Distinctions between Prior and Posterior in Bayesian Statistics", out.width='11cm'}
#rmddochelper::use_odg_graphic(ps_path = "odg/asmbayespriorposterior.odg")
knitr::include_graphics(path = "odg/asmbayespriorposterior.png")
```


## Posterior Distribution

* How to get to posterior distribution $f(\beta | y)$
* Use regression as example
* $\beta$ is a vector with two components, $\beta^T = \left[\begin{array}{cc} \beta_0  &  \beta_1 \end{array} \right]$
* __Solution__: accumulation of samples from full conditional posterior distributions leads to samples from posterior distribution


## Prior and Likelihood

* What are the distributional assumptions (for regression example and in general)
* Prior: $f(\beta)$ usually assumed to be uniform
* Likelihood: $f(y|\beta)$ assumed to be multivariate normal


## Regression

* Full conditional distributions
    + intercept: $f(\beta_0 | \beta_1, y)$ is a normal distribution
    + slope: $f(\beta_1 | \beta_0, y)$ is normal distribution
* Draw random numbers from full conditional distributions in turn
* Result will be samples from posterior distribution


## Full Conditional Distributions

```{r full-cond-dist, echo=FALSE, hook_convert_odg=TRUE, fig_path="odg", out.width='11cm'}
#rmdhelp::use_odg_graphic(ps_path = "odg/full-cond-dist.odg")
knitr::include_graphics(path = "odg/full-cond-dist.png")
```



## Estimates from Samples

* Given Samples from posterior distribution $f(\beta | y)$
* Estimates are computed as empirical means and standard deviation based on the samples

$$\beta_{Bayes} = {1 \over N}\sum_{t=1}^N \beta^{(t)}$$

with $N$ samples drawn from full conditional distributions


## Gibbs Sampler

* Implementation using full conditional distributions
* Use Gibbs Sampler for regression example
* Step 1: Start with initial values $\beta_0 = \beta_1 = 0$
* Step 2: Compute mean and standard deviation for full conditional distribution of $\beta_0$
* Step 3: Draw random sample for $\beta_0$
* Step 4 and 5: same for $\beta_1$
* Step 6: Repeat 2-5 $N$ times
* Step 7: Compute mean from samples

